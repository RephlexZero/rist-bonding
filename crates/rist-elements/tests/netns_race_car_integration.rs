//! RIST Race Car Integration Test over Network Namespaces
//!
//! This test demonstrates RIST bonding performance under realistic race car
//! cellular network conditions using actual network namespaces with custom IP addressing.
//! It streams H.265 video with dual-channel two-tone sine wave audio over 2x4G + 2x5G
//! bonded connections and measures video quality, packet loss, and recovery performance
//! under challenging conditions.

#[cfg(feature = "netns-sim")]
mod netns_race_car_tests {
    use gstreamer::prelude::*;
    use netns_testbench::{NetworkOrchestrator, TestScenario};
    use std::sync::{Arc, Mutex};
    use std::time::{Duration, Instant};
    use tokio::time::sleep;
    use tracing::{info, error};

    /// Video quality metrics collected during streaming
    #[derive(Default, Debug, Clone)]
    struct VideoQualityMetrics {
        pub frames_sent: u64,
        pub frames_received: u64,
        pub bytes_sent: u64,
        pub bytes_received: u64,
        pub packets_lost: u64,
        pub max_latency_ms: u64,
        pub avg_latency_ms: f64,
        pub jitter_ms: f64,
        pub bitrate_kbps: f64,
        pub frame_drops: u64,
        pub recovery_requests: u64,
    }

    impl VideoQualityMetrics {
        fn frame_loss_percentage(&self) -> f64 {
            if self.frames_sent == 0 { return 0.0; }
            ((self.frames_sent - self.frames_received) as f64 / self.frames_sent as f64) * 100.0
        }
        
        fn effective_bitrate_kbps(&self) -> f64 {
            self.bitrate_kbps
        }
    }

    /// Quality assessment results
    #[derive(Debug)]
    struct QualityAssessment {
        overall_score: f64,  // 0-100, higher is better
        video_quality: VideoQualityMetrics,
        network_conditions: String,
        bonding_effectiveness: f64,
        recommendation: String,
    }

    /// Create sender pipeline with H.265 video and dual-channel two-tone sine wave audio for race car testing
    fn build_race_car_sender_pipeline(bonding_addresses: &[String]) -> Result<(gstreamer::Pipeline, Arc<Mutex<VideoQualityMetrics>>), Box<dyn std::error::Error>> {
        let pipeline = gstreamer::Pipeline::new();
        let metrics = Arc::new(Mutex::new(VideoQualityMetrics::default()));
        
        // High-quality test video source (simulating race car onboard camera)
        let videotestsrc = gstreamer::ElementFactory::make("videotestsrc")
            .property("is-live", true)
            .build()
            .expect("Failed to create videotestsrc");

        // Dual-channel two-tone sine wave audio sources for race car testing
    let audiotestsrc_left = gstreamer::ElementFactory::make("audiotestsrc")
            .property("is-live", true)
            .property("freq", 440.0) // A4 note for left channel
            .property("volume", 0.5)
            .build()
            .expect("Failed to create left channel audiotestsrc");

    let audiotestsrc_right = gstreamer::ElementFactory::make("audiotestsrc")
            .property("is-live", true)
            .property("freq", 523.0) // C5 note for right channel
            .property("volume", 0.5)
            .build()
            .expect("Failed to create right channel audiotestsrc");

        // Video processing chain - 1080p60 H.265
        let videoconvert = gstreamer::ElementFactory::make("videoconvert")
            .build()
            .expect("Failed to create videoconvert");
            
        let videoscale = gstreamer::ElementFactory::make("videoscale")
            .build()
            .expect("Failed to create videoscale");

        // High-quality 1080p60 video caps
        let video_caps = gstreamer::Caps::builder("video/x-raw")
            .field("width", 1920)
            .field("height", 1080)
            .field("framerate", gstreamer::Fraction::new(60, 1))
            .field("format", "I420")
            .build();
            
        let video_capsfilter = gstreamer::ElementFactory::make("capsfilter")
            .property("caps", &video_caps)
            .build()
            .expect("Failed to create video capsfilter");

        // H.265 encoder with race car optimizations
        let x265enc = gstreamer::ElementFactory::make("x265enc")
            .property("bitrate", 8000u32) // 8 Mbps for high quality
            .property("key-int-max", 60i32) // IDR every 1 second
            .build()
            .expect("Failed to create x265enc");

        // RTP H.265 payloader
        let rtph265pay = gstreamer::ElementFactory::make("rtph265pay")
            .property("pt", 96u32)
            .property("config-interval", 1i32) // Send VPS/SPS/PPS frequently
            .build()
            .expect("Failed to create rtph265pay");

        // Audio processing chain with mixing for dual-channel two-tone
        let audiomixer = gstreamer::ElementFactory::make("audiomixer")
            .build()
            .expect("Failed to create audiomixer");
            
        let audioconvert = gstreamer::ElementFactory::make("audioconvert")
            .build()
            .expect("Failed to create audioconvert");
            
        let audioresample = gstreamer::ElementFactory::make("audioresample")
            .build()
            .expect("Failed to create audioresample");

        // High-quality audio caps (L16 RTP requires big endian)
        let audio_caps = gstreamer::Caps::builder("audio/x-raw")
            .field("format", "S16BE") // Big endian for L16 RTP
            .field("layout", "interleaved")
            .field("channels", 2) // Stereo
            .field("rate", 44100) // Use 44.1kHz to match RTP static PT=11 for L16 stereo
            .build();
            
        let audio_capsfilter = gstreamer::ElementFactory::make("capsfilter")
            .property("caps", &audio_caps)
            .build()
            .expect("Failed to create audio capsfilter");

        // RTP L16 payloader (raw audio)
        let rtp_l16pay = gstreamer::ElementFactory::make("rtpL16pay")
            .property("pt", 11u32) // Static PT=11: L16, 44.1kHz, stereo
            .build()
            .expect("Failed to create rtpL16pay");

        // RTP muxer for combining video and audio
        let rtpmux = gstreamer::ElementFactory::make("rtpmux")
            .build()
            .expect("Failed to create rtpmux");
        // Set a fixed SSRC with even LSB for the combined RTP stream
        let ssrc_value: u32 = 0x12345678u32 & !1u32;
        rtpmux.set_property("ssrc", &ssrc_value);

        // Queues before muxer to decouple audio/video rates
        let q_video = gstreamer::ElementFactory::make("queue")
            .build()
            .expect("Failed to create video queue");
        let q_audio = gstreamer::ElementFactory::make("queue")
            .build()
            .expect("Failed to create audio queue");

        // Capsfilter to provide SSRC in caps for ristsink (required by element)
        let ssrc_caps = gstreamer::Caps::builder("application/x-rtp")
            .field("ssrc", ssrc_value as u32)
            .build();
        let rtp_ssrc_capsfilter = gstreamer::ElementFactory::make("capsfilter")
            .property("caps", &ssrc_caps)
            .build()
            .expect("Failed to create RTP SSRC capsfilter");

        // Create RIST sink with bonding addresses
        let bonding_addresses_str = bonding_addresses.join(",");
        let ristsink = gstreamer::ElementFactory::make("ristsink")
            .property("bonding-addresses", &bonding_addresses_str)
            .property("sender-buffer", 1200u32) // Default 1200ms retransmission buffer
            .property("stats-update-interval", 1000u32)
            .build()
            .expect("Failed to create ristsink");

        // Ensure rtpbin inside ristsink has a reasonable latency to compute running time
        // and schedule RTCP properly. This avoids 'running time not set' warnings.
        if let Ok(bin) = ristsink.clone().dynamic_cast::<gstreamer::Bin>() {
            if let Some(child) = bin.by_name("rist_send_rtpbin") {
                // Best-effort; if property isn't found, ignore.
                let _ = child.set_property("latency", 200u32);
            }
        }

        // Add all elements to pipeline
        pipeline.add_many([
            &videotestsrc, &videoconvert, &videoscale, &video_capsfilter, &x265enc, &rtph265pay, &q_video,
            &audiotestsrc_left, &audiotestsrc_right, &audiomixer, &audioconvert, &audioresample, &audio_capsfilter, &rtp_l16pay, &q_audio,
            &rtpmux, &rtp_ssrc_capsfilter, &ristsink
        ]).expect("Failed to add elements to pipeline");

        // Link video chain
        gstreamer::Element::link_many([
            &videotestsrc, &videoconvert, &videoscale, &video_capsfilter, &x265enc, &rtph265pay
        ]).expect("Failed to link video chain");

        // Link audio chain with dual-channel mixing
        audiotestsrc_left.link(&audiomixer).expect("Failed to link left channel to mixer");
        audiotestsrc_right.link(&audiomixer).expect("Failed to link right channel to mixer");
        
        gstreamer::Element::link_many([
            &audiomixer, &audioconvert, &audioresample, &audio_capsfilter, &rtp_l16pay
        ]).expect("Failed to link audio chain");

        // Connect payloaders via queues to muxer
        rtph265pay.link(&q_video).expect("Failed to link video pay to queue");
        q_video.link(&rtpmux).expect("Failed to link video queue to muxer");
        rtp_l16pay.link(&q_audio).expect("Failed to link audio pay to queue");
        q_audio.link(&rtpmux).expect("Failed to link audio queue to muxer");

        // Connect muxer -> SSRC capsfilter -> RIST sink
        rtpmux
            .link(&rtp_ssrc_capsfilter)
            .expect("Failed to link rtpmux to ssrc capsfilter");
        rtp_ssrc_capsfilter
            .link(&ristsink)
            .expect("Failed to link ssrc capsfilter to ristsink");

        Ok((pipeline, metrics))
    }

    /// Create receiver pipeline for race car testing with quality assessment
    fn build_race_car_receiver_pipeline(listen_port: u16) -> Result<(gstreamer::Pipeline, Arc<Mutex<VideoQualityMetrics>>), Box<dyn std::error::Error>> {
        let pipeline = gstreamer::Pipeline::new();
        let metrics = Arc::new(Mutex::new(VideoQualityMetrics::default()));

        // RIST source
        let ristsrc = gstreamer::ElementFactory::make("ristsrc")
            .property("address", "0.0.0.0")
            .property("port", listen_port as u32)
            .property("encoding-name", "H265")
            .build()
            .expect("Failed to create ristsrc");

        // Help rtpbin inside ristsrc with a sensible latency value
        if let Ok(bin) = ristsrc.clone().dynamic_cast::<gstreamer::Bin>() {
            if let Some(child) = bin.by_name("rist_recv_rtpbin") {
                let _ = child.set_property("latency", 200u32);
            }
        }

        // RTP demuxer
        let rtpptdemux = gstreamer::ElementFactory::make("rtpptdemux")
            .build()
            .expect("Failed to create rtpptdemux");

        // Video chain
        let rtph265depay = gstreamer::ElementFactory::make("rtph265depay")
            .build()
            .expect("Failed to create rtph265depay");

        let avdec_h265 = gstreamer::ElementFactory::make("avdec_h265")
            .build()
            .expect("Failed to create avdec_h265");

        let videoconvert = gstreamer::ElementFactory::make("videoconvert")
            .build()
            .expect("Failed to create videoconvert");

        // Video counter sink for testing
        let video_counter = gstreamer::ElementFactory::make("appsink")
            .property("emit-signals", true)
            .property("max-buffers", 1u32)
            .property("drop", true)
            .build()
            .expect("Failed to create video counter");

        // Audio chain
        let rtpopusdepay = gstreamer::ElementFactory::make("rtpopusdepay")
            .build()
            .expect("Failed to create rtpopusdepay");

        let opusdec = gstreamer::ElementFactory::make("opusdec")
            .build()
            .expect("Failed to create opusdec");

        let audioconvert = gstreamer::ElementFactory::make("audioconvert")
            .build()
            .expect("Failed to create audioconvert");

        // Audio counter sink for testing
        let audio_counter = gstreamer::ElementFactory::make("appsink")
            .property("emit-signals", true)
            .property("max-buffers", 1u32)
            .property("drop", true)
            .build()
            .expect("Failed to create audio counter");

        // Add elements to pipeline
        pipeline.add_many([
            &ristsrc, &rtpptdemux,
            &rtph265depay, &avdec_h265, &videoconvert, &video_counter,
            &rtpopusdepay, &opusdec, &audioconvert, &audio_counter
        ]).expect("Failed to add receiver elements");

        // Link initial chain
        ristsrc.link(&rtpptdemux).expect("Failed to link ristsrc to demuxer");

        // Link video chain
        gstreamer::Element::link_many([
            &rtph265depay, &avdec_h265, &videoconvert, &video_counter
        ]).expect("Failed to link video receive chain");

        // Link audio chain
        gstreamer::Element::link_many([
            &rtpopusdepay, &opusdec, &audioconvert, &audio_counter
        ]).expect("Failed to link audio receive chain");

        // Connect demuxer pads dynamically
        let video_depay_clone = rtph265depay.clone();
        let audio_depay_clone = rtpopusdepay.clone();
        
        rtpptdemux.connect_pad_added(move |_element, src_pad| {
            let pad_name = src_pad.name();
            if pad_name.as_str().contains("96") {
                // H.265 video
                if let Some(sink_pad) = video_depay_clone.static_pad("sink") {
                    let _ = src_pad.link(&sink_pad);
                }
            } else if pad_name.as_str().contains("11") {
                // L16 stereo audio (PT=11)
                if let Some(sink_pad) = audio_depay_clone.static_pad("sink") {
                    let _ = src_pad.link(&sink_pad);
                }
            }
        });

        // Set up buffer counting
        let metrics_clone = metrics.clone();
        video_counter.connect("new-sample", false, {
            let metrics = metrics_clone.clone();
            move |_| {
                let mut metrics_guard = metrics.lock().unwrap();
                metrics_guard.frames_received += 1;
                None
            }
        });

        Ok((pipeline, metrics))
    }

    /// Build a receiver pipeline with H.265 video and dual-channel audio output to MP4 file
    fn build_race_car_receiver_pipeline_with_video_output(
        rx_port: u16,
        metrics: Arc<Mutex<VideoQualityMetrics>>,
        output_filename: &str,
    ) -> Result<gstreamer::Pipeline, Box<dyn std::error::Error>> {
        // Create pipeline
        let pipeline = gstreamer::Pipeline::new();

        // Create RIST source - receiver just binds to port, sender does the bonding
        let ristsrc = gstreamer::ElementFactory::make("ristsrc")
            // ristsrc uses separate address + port; 'receiver-buffer' controls buffering in ms
            .property("address", "0.0.0.0")
            .property("port", rx_port as u32)
            .property("receiver-buffer", 1000u32)
            .property("stats-update-interval", 1000u32)
            // Hint the encoding so rtpbin can set correct caps for dynamic PT=96
            .property("encoding-name", "H265")
            .build()
            .expect("Failed to create ristsrc");

        // RTP PT demuxer to split video/audio based on payload type
        let rtpptdemux = gstreamer::ElementFactory::make("rtpptdemux")
            .build()
            .expect("Failed to create rtpptdemux");

        // Video elements (keep encoded for MP4 muxing)
        let video_depay = gstreamer::ElementFactory::make("rtph265depay")
            .build()
            .expect("Failed to create rtph265depay");

        let video_parse = gstreamer::ElementFactory::make("h265parse")
            .property("config-interval", 1i32) // ensure codec config in-stream for mp4
            .build()
            .expect("Failed to create h265parse");

        // Audio elements
        let audio_depay = gstreamer::ElementFactory::make("rtpL16depay")
            .build()
            .expect("Failed to create rtpL16depay");

        let audioconvert = gstreamer::ElementFactory::make("audioconvert")
            .build()
            .expect("Failed to create audioconvert");

        let audioresample = gstreamer::ElementFactory::make("audioresample")
            .build()
            .expect("Failed to create audioresample");

        let audio_encode = gstreamer::ElementFactory::make("avenc_aac")
            .property("bitrate", 128000i32)
            .build()
            .expect("Failed to create avenc_aac");

        // MP4 muxer and file sink
        let mp4mux = gstreamer::ElementFactory::make("mp4mux")
            .property("streamable", true)
            .build()
            .expect("Failed to create mp4mux");

        let filesink = gstreamer::ElementFactory::make("filesink")
            .property("location", output_filename)
            .build()
            .expect("Failed to create filesink");

        // Add elements to pipeline
        pipeline.add_many(&[
            &ristsrc,
            &rtpptdemux,
            &video_depay,
            &video_parse,
            &audio_depay,
            &audioconvert,
            &audioresample,
            &audio_encode,
            &mp4mux,
            &filesink,
        ])?;

        // Link static chains
        ristsrc.link(&rtpptdemux)?;
        video_depay.link(&video_parse)?;
        audio_depay.link(&audioconvert)?;
        audioconvert.link(&audioresample)?;
        audioresample.link(&audio_encode)?;
        mp4mux.link(&filesink)?;

        // Connect RTP PT demuxer pad-added for dynamic pad linking
        let video_depay_clone = video_depay.clone();
        let audio_depay_clone = audio_depay.clone();
    rtpptdemux.connect_pad_added(move |_element, src_pad| {
            let pad_name = src_pad.name();
            if pad_name.as_str().contains("96") {
                if let Some(sink_pad) = video_depay_clone.static_pad("sink") {
                    let _ = src_pad.link(&sink_pad);
                    info!("Linked video RTP (PT=96)");
                }
        } else if pad_name.as_str().contains("11") {
                if let Some(sink_pad) = audio_depay_clone.static_pad("sink") {
                    let _ = src_pad.link(&sink_pad);
            info!("Linked audio RTP (PT=11)");
                }
            }
        });

    // Connect elementary streams to muxer request pads (mp4mux uses video_%u/audio_%u)
    let video_pad = video_parse.static_pad("src").unwrap();
    let video_sink_pad = mp4mux.request_pad_simple("video_%u").unwrap();
    video_pad.link(&video_sink_pad)?;

    // Connect audio to muxer (AAC)
    let audio_pad = audio_encode.static_pad("src").unwrap();
    let audio_sink_pad = mp4mux.request_pad_simple("audio_%u").unwrap();
    audio_pad.link(&audio_sink_pad)?;

        // Add a buffer probe to count received video buffers/bytes
        if let Some(vsrc) = video_parse.static_pad("src") {
            let metrics_weak: std::sync::Weak<Mutex<VideoQualityMetrics>> = Arc::downgrade(&metrics);
            vsrc.add_probe(gstreamer::PadProbeType::BUFFER, move |_pad, info| {
                if let Some(gstreamer::PadProbeData::Buffer(ref buf)) = &info.data {
                    if let Some(metrics) = metrics_weak.upgrade() {
                        let mut m = metrics.lock().unwrap();
                        m.frames_received += 1;
                        m.bytes_received += buf.size() as u64;
                    }
                }
                gstreamer::PadProbeReturn::Ok
            });
        }

        Ok(pipeline)
    }

    /// Minimal video-only sender to isolate RIST transport (no audio, no rtpmux)
    /// videotestsrc (1080p60) -> x265enc -> rtph265pay(pt=96) -> caps(filter full RTP caps incl. SSRC) -> ristsink
    fn build_video_only_sender_pipeline(bonding_addresses: &[String]) -> Result<gstreamer::Pipeline, Box<dyn std::error::Error>> {
        let pipeline = gstreamer::Pipeline::new();

        // Live test source
        let videotestsrc = gstreamer::ElementFactory::make("videotestsrc")
            .property("is-live", true)
            .property("do-timestamp", true)
            .build()
            .expect("Failed to create videotestsrc");

        let videoconvert = gstreamer::ElementFactory::make("videoconvert")
            .build()
            .expect("Failed to create videoconvert");

        let videoscale = gstreamer::ElementFactory::make("videoscale")
            .build()
            .expect("Failed to create videoscale");

        let video_caps = gstreamer::Caps::builder("video/x-raw")
            .field("width", 1920)
            .field("height", 1080)
            .field("framerate", gstreamer::Fraction::new(60, 1))
            .field("format", "I420")
            .build();
        let video_capsfilter = gstreamer::ElementFactory::make("capsfilter")
            .property("caps", &video_caps)
            .build()
            .expect("Failed to create video capsfilter");

        let x265enc = gstreamer::ElementFactory::make("x265enc")
            .property("bitrate", 6000u32)
            .property("key-int-max", 60i32)
            .build()
            .expect("Failed to create x265enc");

        let rtph265pay = gstreamer::ElementFactory::make("rtph265pay")
            .property("pt", 96u32)
            .property("config-interval", 1i32)
            .build()
            .expect("Failed to create rtph265pay");

        // Provide full RTP caps upstream for ristsink (media, encoding-name, payload, clock-rate, ssrc)
        let ssrc_value: u32 = 0x2468ACE0u32 & !1u32; // even SSRC
        let rtp_caps = gstreamer::Caps::builder("application/x-rtp")
            .field("media", "video")
            .field("encoding-name", "H265")
            .field("payload", 96i32)
            .field("clock-rate", 90000i32)
            .field("ssrc", ssrc_value as u32)
            .build();
        let rtp_capsfilter = gstreamer::ElementFactory::make("capsfilter")
            .property("caps", &rtp_caps)
            .build()
            .expect("Failed to create RTP capsfilter");

        let bonding_addresses_str = bonding_addresses.join(",");
        let ristsink = gstreamer::ElementFactory::make("ristsink")
            .property("bonding-addresses", &bonding_addresses_str)
            .property("sender-buffer", 1200u32)
            .property("stats-update-interval", 1000u32)
            .build()
            .expect("Failed to create ristsink");

        pipeline.add_many(&[&videotestsrc, &videoconvert, &videoscale, &video_capsfilter, &x265enc, &rtph265pay, &rtp_capsfilter, &ristsink])?;
        gstreamer::Element::link_many(&[&videotestsrc, &videoconvert, &videoscale, &video_capsfilter, &x265enc, &rtph265pay, &rtp_capsfilter, &ristsink])?;

        Ok(pipeline)
    }

    /// Minimal video-only receiver writing MP4 (H.265 elementary stream kept encoded)
    /// ristsrc -> rtph265depay -> h265parse -> mp4mux -> filesink
    fn build_video_only_receiver_pipeline_with_output(
        rx_port: u16,
        metrics: Arc<Mutex<VideoQualityMetrics>>,
        output_filename: &str,
    ) -> Result<gstreamer::Pipeline, Box<dyn std::error::Error>> {
        let pipeline = gstreamer::Pipeline::new();

        let ristsrc = gstreamer::ElementFactory::make("ristsrc")
            .property("address", "0.0.0.0")
            .property("port", rx_port as u32)
            .property("receiver-buffer", 1000u32)
            .property("stats-update-interval", 1000u32)
            .property("encoding-name", "H265")
            .build()
            .expect("Failed to create ristsrc");

        let rtph265depay = gstreamer::ElementFactory::make("rtph265depay")
            .build()
            .expect("Failed to create rtph265depay");

        let h265parse = gstreamer::ElementFactory::make("h265parse")
            .property("config-interval", 1i32)
            .build()
            .expect("Failed to create h265parse");

        let mp4mux = gstreamer::ElementFactory::make("mp4mux")
            .property("streamable", true)
            .build()
            .expect("Failed to create mp4mux");

        let filesink = gstreamer::ElementFactory::make("filesink")
            .property("location", output_filename)
            .build()
            .expect("Failed to create filesink");

        pipeline.add_many(&[&ristsrc, &rtph265depay, &h265parse, &mp4mux, &filesink])?;
        ristsrc.link(&rtph265depay)?;
        rtph265depay.link(&h265parse)?;
        mp4mux.link(&filesink)?;

    // Link encoded video to muxer request pad
    let video_pad = h265parse.static_pad("src").unwrap();
    let video_sink_pad = mp4mux.request_pad_simple("video_%u").unwrap();
    video_pad.link(&video_sink_pad)?;

        // Count received encoded buffers
        if let Some(vsrc) = h265parse.static_pad("src") {
            let metrics_weak: std::sync::Weak<Mutex<VideoQualityMetrics>> = Arc::downgrade(&metrics);
            vsrc.add_probe(gstreamer::PadProbeType::BUFFER, move |_pad, info| {
                if let Some(gstreamer::PadProbeData::Buffer(ref buf)) = &info.data {
                    if let Some(metrics) = metrics_weak.upgrade() {
                        let mut m = metrics.lock().unwrap();
                        m.frames_received += 1;
                        m.bytes_received += buf.size() as u64;
                    }
                }
                gstreamer::PadProbeReturn::Ok
            });
        }

        Ok(pipeline)
    }

    /// Build a single-session MPEG-TS over RTP (PT=33) sender carried over one RIST stream
    fn build_ts_over_rtp_sender_pipeline(bonding_address: &str) -> Result<gstreamer::Pipeline, Box<dyn std::error::Error>> {
        let pipeline = gstreamer::Pipeline::new();

        // Video: H.265 elementary stream
        let vsrc = gstreamer::ElementFactory::make("videotestsrc")
            .property("is-live", true)
            .property("do-timestamp", true)
            .build()?;
        let vconv = gstreamer::ElementFactory::make("videoconvert").build()?;
        let vscale = gstreamer::ElementFactory::make("videoscale").build()?;
        let v_caps = gstreamer::Caps::builder("video/x-raw")
            .field("width", 1920)
            .field("height", 1080)
            .field("framerate", gstreamer::Fraction::new(60, 1))
            .field("format", "I420")
            .build();
        let vcap = gstreamer::ElementFactory::make("capsfilter").property("caps", &v_caps).build()?;
        let venc = gstreamer::ElementFactory::make("x265enc").property("bitrate", 8000u32).property("key-int-max", 15i32).build()?;
        let vparse = gstreamer::ElementFactory::make("h265parse").build()?;

        // Audio: AAC elementary stream from stereo two-tone
        let asrc_l = gstreamer::ElementFactory::make("audiotestsrc").property("is-live", true).property("freq", 440.0f64).property("volume", 0.5f64).build()?;
        let asrc_r = gstreamer::ElementFactory::make("audiotestsrc").property("is-live", true).property("freq", 523.0f64).property("volume", 0.5f64).build()?;
        let amix = gstreamer::ElementFactory::make("audiomixer").build()?;
        let aconv = gstreamer::ElementFactory::make("audioconvert").build()?;
        let ares = gstreamer::ElementFactory::make("audioresample").build()?;
        let aenc = gstreamer::ElementFactory::make("avenc_aac").property("bitrate", 128000i32).build()?;
        let aparse = gstreamer::ElementFactory::make("aacparse").build()?;

        // Mux into MPEG-TS, then RTP payload
        let tsmux = gstreamer::ElementFactory::make("mpegtsmux").build()?;
        // Tee off raw TS for debugging
        let ts_tee = gstreamer::ElementFactory::make("tee").build()?;
        let tsq_file = gstreamer::ElementFactory::make("queue").build()?;
        let ts_file = gstreamer::ElementFactory::make("filesink")
            .property("location", "sender_debug.ts")
            .build()?;
        let rtpmp2tpay = gstreamer::ElementFactory::make("rtpmp2tpay").property("pt", 33u32).build()?;

        // Provide full RTP caps expected by ristsink for MP2T
        let ssrc_value: u32 = 0x13572468 & !1; // even
        let rtp_caps = gstreamer::Caps::builder("application/x-rtp")
            .field("media", "video")
            .field("encoding-name", "MP2T")
            .field("payload", 33i32)
            .field("clock-rate", 90000i32)
            .field("ssrc", ssrc_value)
            .build();
        let rtp_cf = gstreamer::ElementFactory::make("capsfilter").property("caps", &rtp_caps).build()?;

        let ristsink = gstreamer::ElementFactory::make("ristsink")
            .property("bonding-addresses", bonding_address)
            // Give retransmission more room (ms)
            .property("sender-buffer", 5000u32)
            .property("stats-update-interval", 1000u32)
            .build()?;

        // Assemble
    pipeline.add_many(&[&vsrc, &vconv, &vscale, &vcap, &venc, &vparse, &asrc_l, &asrc_r, &amix, &aconv, &ares, &aenc, &aparse, &tsmux, &ts_tee, &tsq_file, &ts_file, &rtpmp2tpay, &rtp_cf, &ristsink])?;

        // Video branch
        gstreamer::Element::link_many(&[&vsrc, &vconv, &vscale, &vcap, &venc, &vparse])?;
        // Audio branch
        asrc_l.link(&amix)?;
        asrc_r.link(&amix)?;
        gstreamer::Element::link_many(&[&amix, &aconv, &ares, &aenc, &aparse])?;

        // Link mux request pads for video+audio (mpegtsmux uses sink_%d)
        let v_pad = vparse.static_pad("src").unwrap();
        let v_sink = tsmux.request_pad_simple("sink_%d").unwrap();
        v_pad.link(&v_sink)?;

        let a_pad = aparse.static_pad("src").unwrap();
        let a_sink = tsmux.request_pad_simple("sink_%d").unwrap();
        a_pad.link(&a_sink)?;

    // Mux to RTP to RIST, and also write TS to file for debugging
    tsmux.link(&ts_tee)?;
    // Branch 1: TS -> file
    gstreamer::Element::link_many(&[&ts_tee, &tsq_file, &ts_file])?;
    // Branch 2: TS -> RTP -> RIST
    let ts_tee_pad = ts_tee.request_pad_simple("src_%u").unwrap();
    let rtp_sink_pad = rtpmp2tpay.static_pad("sink").unwrap();
    ts_tee_pad.link(&rtp_sink_pad)?;
    gstreamer::Element::link_many(&[&rtpmp2tpay, &rtp_cf, &ristsink])?;

        Ok(pipeline)
    }

    /// Build a receiver for single-session MPEG-TS over RTP carried over one RIST stream
    fn build_ts_over_rtp_receiver_pipeline_with_output(
        rx_port: u16,
        metrics: Arc<Mutex<VideoQualityMetrics>>,
        output_filename: &str,
    ) -> Result<gstreamer::Pipeline, Box<dyn std::error::Error>> {
        let pipeline = gstreamer::Pipeline::new();

        let ristsrc = gstreamer::ElementFactory::make("ristsrc")
            .property("address", "0.0.0.0")
            .property("port", rx_port as u32)
            // Increase receiver buffer to cover RTT+jitter for RTX (ms)
            .property("receiver-buffer", 5000u32)
            .property("stats-update-interval", 1000u32)
            .property("encoding-name", "MP2T")
            .build()?;

        let rtpmp2tdepay = gstreamer::ElementFactory::make("rtpmp2tdepay").build()?;
        // Tee off raw TS after depay for debugging
        let rx_ts_tee = gstreamer::ElementFactory::make("tee").build()?;
        let rx_tsq_file = gstreamer::ElementFactory::make("queue").build()?;
        let rx_ts_file = gstreamer::ElementFactory::make("filesink")
            .property("location", "receiver_debug.ts")
            .build()?;
        let rx_tsq_demux = gstreamer::ElementFactory::make("queue").build()?;
        let tsdemux = gstreamer::ElementFactory::make("tsdemux").build()?;

        let h265parse = gstreamer::ElementFactory::make("h265parse")
            .property("config-interval", 1i32)
            .build()?;
        // Force H.265 parser to output an MP4-friendly stream-format
        let h265_caps = gstreamer::Caps::builder("video/x-h265")
            .field("stream-format", "hvc1")
            .field("alignment", "au")
            .build();
        let h265_capsfilter = gstreamer::ElementFactory::make("capsfilter")
            .property("caps", &h265_caps)
            .build()?;

        let aacparse = gstreamer::ElementFactory::make("aacparse")
            .property("disable-passthrough", true)
            .build()?;
        // Ensure raw AAC for mp4mux
        let aac_caps = gstreamer::Caps::builder("audio/mpeg")
            .field("mpegversion", 4i32)
            .field("stream-format", "raw")
            .build();
        let aac_capsfilter = gstreamer::ElementFactory::make("capsfilter")
            .property("caps", &aac_caps)
            .build()?;

        let mp4mux = gstreamer::ElementFactory::make("mp4mux").property("streamable", true).build()?;
        let filesink = gstreamer::ElementFactory::make("filesink").property("location", output_filename).build()?;

    pipeline.add_many(&[&ristsrc, &rtpmp2tdepay, &rx_ts_tee, &rx_tsq_file, &rx_ts_file, &rx_tsq_demux, &tsdemux, &h265parse, &h265_capsfilter, &aacparse, &aac_capsfilter, &mp4mux, &filesink])?;
    
    // Add probe on tsdemux sink to monitor when TS packets stop arriving after RTP depacketization
    tsdemux.static_pad("sink").unwrap().add_probe(gstreamer::PadProbeType::BUFFER, move |_pad, info| {
        if let Some(gstreamer::PadProbeData::Buffer(buffer)) = &info.data {
            if let Some(pts) = buffer.pts() {
                if pts.seconds() % 5 == 0 && pts.nseconds() < 50_000_000 { // Every 5s
                    info!("üéûÔ∏è tsdemux receiving TS buffer: size={} pts={:.3}s", buffer.size(), pts.seconds() as f64 + pts.nseconds() as f64 / 1e9);
                }
            }
        }
        gstreamer::PadProbeReturn::Ok
    });

        ristsrc.link(&rtpmp2tdepay)?;
    // Split TS: branch to file and to demux
    rtpmp2tdepay.link(&rx_ts_tee)?;
    // Branch 1: TS to file
    gstreamer::Element::link_many(&[&rx_ts_tee, &rx_tsq_file, &rx_ts_file])?;
    // Branch 2: TS to demux
    let rx_ts_src_pad = rx_ts_tee.request_pad_simple("src_%u").unwrap();
    let rx_demux_sink = rx_tsq_demux.static_pad("sink").unwrap();
    rx_ts_src_pad.link(&rx_demux_sink)?;
    rx_tsq_demux.link(&tsdemux)?;
    mp4mux.link(&filesink)?;

        // Dynamic link from tsdemux based on caps type (fall back to pad name if caps unavailable)
        let h265parse_clone = h265parse.clone();
        let aacparse_clone = aacparse.clone();
        tsdemux.connect_pad_added(move |_demux, src_pad| {
            if let Some(caps) = src_pad.current_caps() {
                if let Some(s) = caps.structure(0) {
                    info!("üé¨ tsdemux pad-added: {} caps: {}", src_pad.name(), s.to_string());
                }
            } else {
                info!("üé¨ tsdemux pad-added: {} (no caps yet)", src_pad.name());
            }
            let mut linked = false;
            if let Some(caps) = src_pad.current_caps() {
                if let Some(s) = caps.structure(0) {
                    let name = s.name();
                    if name.starts_with("video/x-h265") {
                        if let Some(sink) = h265parse_clone.static_pad("sink") { 
                            let _ = src_pad.link(&sink); 
                            linked = true; 
                            info!("‚úÖ Linked H.265 video pad: {}", src_pad.name());
                        }
                    } else if name.starts_with("audio/mpeg") {
                        if let Some(sink) = aacparse_clone.static_pad("sink") { 
                            let _ = src_pad.link(&sink); 
                            linked = true; 
                            info!("‚úÖ Linked AAC audio pad: {}", src_pad.name());
                        }
                    }
                }
            }
            if !linked {
                let padname = src_pad.name();
                info!("üîÑ Fallback linking by pad name: {}", padname);
                if padname.starts_with("video_") {
                    if let Some(sink) = h265parse_clone.static_pad("sink") { 
                        let _ = src_pad.link(&sink); 
                        info!("‚úÖ Fallback linked video pad: {}", padname);
                    }
                } else if padname.starts_with("audio_") {
                    if let Some(sink) = aacparse_clone.static_pad("sink") { 
                        let _ = src_pad.link(&sink); 
                        info!("‚úÖ Fallback linked audio pad: {}", padname);
                    }
                }
            }
        });

        // Connect parsers to mp4mux
    // h265parse -> capsfilter -> mp4mux(video)
    h265parse.link(&h265_capsfilter)?;
    let vsrc = h265_capsfilter.static_pad("src").unwrap();
    let vpad = mp4mux.request_pad_simple("video_%u").unwrap();
    vsrc.link(&vpad)?;

    // aacparse -> capsfilter -> mp4mux(audio)
    aacparse.link(&aac_capsfilter)?;
    let asrc = aac_capsfilter.static_pad("src").unwrap();
    let apad = mp4mux.request_pad_simple("audio_%u").unwrap();
    asrc.link(&apad)?;

        // Verify TS depayloading by probing rtpmp2tdepay src
        if let Some(ts_src) = rtpmp2tdepay.static_pad("src") {
            let metrics_weak: std::sync::Weak<Mutex<VideoQualityMetrics>> = Arc::downgrade(&metrics);
            ts_src.add_probe(gstreamer::PadProbeType::BUFFER, move |_pad, info| {
                if let Some(gstreamer::PadProbeData::Buffer(ref buf)) = &info.data {
                    if let Some(metrics) = metrics_weak.upgrade() {
                        let mut m = metrics.lock().unwrap();
                        m.bytes_received += buf.size() as u64;
                    }
                }
                gstreamer::PadProbeReturn::Ok
            });
        }

        // Count received video buffers
        if let Some(vsrcpad) = h265parse.static_pad("src") {
            let metrics_weak: std::sync::Weak<Mutex<VideoQualityMetrics>> = Arc::downgrade(&metrics);
            vsrcpad.add_probe(gstreamer::PadProbeType::BUFFER, move |_pad, info| {
                if let Some(gstreamer::PadProbeData::Buffer(ref buf)) = &info.data {
                    if let Some(metrics) = metrics_weak.upgrade() {
                        let mut m = metrics.lock().unwrap();
                        m.frames_received += 1;
                        m.bytes_received += buf.size() as u64;
                    }
                }
                gstreamer::PadProbeReturn::Ok
            });
        }

        Ok(pipeline)
    }

    /// Set up race car network scenarios with realistic cellular bonding
    async fn setup_race_car_network_scenarios(rx_port: u16) -> Result<(NetworkOrchestrator, Vec<String>), Box<dyn std::error::Error>> {
        info!("Setting up race car cellular network scenarios");
        
        // Use timestamp-based seed to avoid namespace conflicts
        let unique_seed = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        let mut orchestrator = NetworkOrchestrator::new(unique_seed).await?;
        
                // Use available scenarios since race car specific scenarios might not exist yet
        let scenarios = vec![
            TestScenario::baseline_good(),
            TestScenario::bonding_asymmetric(),
            TestScenario::mobile_handover(),
            TestScenario::degrading_network(),
        ];
        
        // Stand up links to exercise netns creation/cleanup,
        // but for the actual end-to-end streaming we target the first link only
        for (i, scenario) in scenarios.into_iter().enumerate() {
            let _ = orchestrator.start_scenario(scenario, rx_port + i as u16).await?;
        }

    // For link_1 the addressing (aligned /30) is 10.0.0.9/30 (tx) <-> 10.0.0.10/30 (rx)
    // We will run one sender inside tx0_link_1 targeting the receiver in rx0_link_1 on rx_port
    let bonding_addresses = vec![format!("{}:{}", "10.0.0.10", rx_port)];

        Ok((orchestrator, bonding_addresses))
    }

    /// Assess video quality based on metrics
    fn assess_video_quality(metrics: &VideoQualityMetrics, _duration_secs: u64, network_conditions: &str) -> QualityAssessment {
        let mut score = 100.0;
        let mut issues = Vec::new();
        
        // Frame loss assessment
        let frame_loss_pct = metrics.frame_loss_percentage();
        if frame_loss_pct > 5.0 {
            score -= 30.0;
            issues.push(format!("High frame loss: {:.2}%", frame_loss_pct));
        } else if frame_loss_pct > 1.0 {
            score -= 10.0;
            issues.push(format!("Moderate frame loss: {:.2}%", frame_loss_pct));
        }
        
        // Latency assessment
        if metrics.avg_latency_ms > 500.0 {
            score -= 25.0;
            issues.push(format!("High latency: {:.0}ms", metrics.avg_latency_ms));
        } else if metrics.avg_latency_ms > 200.0 {
            score -= 10.0;
            issues.push(format!("Moderate latency: {:.0}ms", metrics.avg_latency_ms));
        }
        
        // Bonding effectiveness (based on recovery requests vs packet loss)
        let bonding_effectiveness = if metrics.packets_lost > 0 {
            (metrics.recovery_requests as f64 / metrics.packets_lost as f64).min(1.0) * 100.0
        } else {
            100.0
        };
        
        // Generate recommendation
        let recommendation = if score >= 90.0 {
            "Excellent quality - suitable for professional race car broadcasting".to_string()
        } else if score >= 75.0 {
            "Good quality - suitable for race car streaming with minor artifacts".to_string()
        } else if score >= 60.0 {
            format!("Acceptable quality with issues: {}", issues.join(", "))
        } else {
            format!("Poor quality, significant issues: {}", issues.join(", "))
        };
        
        QualityAssessment {
            overall_score: score,
            video_quality: metrics.clone(),
            network_conditions: network_conditions.to_string(),
            bonding_effectiveness,
            recommendation,
        }
    }

    /// Run comprehensive race car RIST test
    async fn run_race_car_rist_test(duration_secs: u64) -> Result<QualityAssessment, Box<dyn std::error::Error>> {
        info!("üèéÔ∏è  Starting Race Car RIST Integration Test");
        info!("Duration: {}s, Video: 1080p60 H.265, Audio: Dual-Channel Two-Tone Sine Wave", duration_secs);
        
        let rx_port = 8000u16;
        let start_time = Instant::now();
        
        // Set up network scenarios
        let (_orchestrator, bonding_addresses) = setup_race_car_network_scenarios(rx_port).await?;
        
        info!("Network setup complete:");
        for (i, addr) in bonding_addresses.iter().enumerate() {
            info!("  Link {}: {}", i + 1, addr);
        }
        
        // Build pipelines
        let (sender_pipeline, _sender_metrics) = build_race_car_sender_pipeline(&bonding_addresses)?;
        let (receiver_pipeline, receiver_metrics) = build_race_car_receiver_pipeline(rx_port)?;
        
        info!("Pipelines built, starting streaming...");
        
        // Start pipelines
        sender_pipeline.set_state(gstreamer::State::Playing)?;
        receiver_pipeline.set_state(gstreamer::State::Playing)?;
        
        // Monitor streaming for specified duration
        let mut last_report = Instant::now();
        let report_interval = Duration::from_secs(5);
        
        while start_time.elapsed().as_secs() < duration_secs {
            sleep(Duration::from_millis(100)).await;
            
            // Periodic progress reports
            if last_report.elapsed() >= report_interval {
                let receiver_stats = receiver_metrics.lock().unwrap();
                
                info!("Progress: {}s - Received: {} frames",
                      start_time.elapsed().as_secs(),
                      receiver_stats.frames_received);
                
                last_report = Instant::now();
            }
        }
        
        info!("Streaming complete, stopping pipelines...");
        
        // Stop pipelines
        sender_pipeline.set_state(gstreamer::State::Null)?;
        receiver_pipeline.set_state(gstreamer::State::Null)?;
        
        // Collect final metrics
        let final_receiver_metrics = receiver_metrics.lock().unwrap().clone();
        
        // Assess quality
        let assessment = assess_video_quality(&final_receiver_metrics, duration_secs, "Race Car Cellular Bonding");
        
        info!("Test completed in {:.2}s", start_time.elapsed().as_secs_f64());
        
        Ok(assessment)
    }

    /// Run race car RIST test with video file output
    async fn run_race_car_rist_test_with_video_output(duration_secs: u64) -> Result<QualityAssessment, Box<dyn std::error::Error>> {
        info!("üèéÔ∏è  Starting Race Car RIST Integration Test with Video Output");
    info!("Duration: {}s, Video: 1080p60 H.265, Audio: Dual-Channel AAC via MPEG-TS, Output: race_car_test_output.mp4", duration_secs);
        
    let rx_port_ts = 8000u16; // single RIST session carrying MPEG-TS
        let start_time = Instant::now();
        
        // Set up network scenarios with actual network namespaces
    let (_orchestrator, _bonding_addresses) = setup_race_car_network_scenarios(rx_port_ts).await?;
        
        info!("Network setup complete with real network namespaces:");
    info!("  Link 1 TS dst: 10.0.0.10:{} (rx0_link_1)", rx_port_ts);
        
        // Run sender and receiver inside their respective namespaces for link_1
        use netns_testbench::netns::Manager as NetNsManager;

    // Prepare metrics to be updated by the receiver pipeline
        let receiver_metrics = Arc::new(Mutex::new(VideoQualityMetrics::default()));
        
    // Sender task in tx0_link_1 (single RIST session carrying MPEG-TS)
    let ts_addr = format!("10.0.0.10:{}", rx_port_ts);
        let sender_handle = tokio::task::spawn_blocking(move || {
            // Create a fresh manager to attach to the existing namespace
            let mut ns_mgr = NetNsManager::new().expect("Failed to create NetNsManager");
            ns_mgr.attach_existing_namespace("tx0_link_1").expect("Failed to attach tx0_link_1");

            let _ = ns_mgr.exec_in_namespace("tx0_link_1", || {
                // Build and run sender pipeline entirely inside tx namespace
                gstreamer::init().ok();
        let sender_pipeline = build_ts_over_rtp_sender_pipeline(&ts_addr).expect("build sender");

                // Create a dedicated thread-default GLib MainContext and loop
                let ctx = gstreamer::glib::MainContext::new();
                let _ = ctx.with_thread_default(|| {
                    let main_loop = gstreamer::glib::MainLoop::new(Some(&ctx), false);

                    // Best-effort: increase internal rtpbin latency if present
                    let pipeline_clone = sender_pipeline.clone();
                    gstreamer::glib::idle_add_local(move || {
                        let mut it = pipeline_clone.iterate_elements();
                        while let Ok(Some(elem)) = it.next() {
                            if let Some(factory) = elem.factory() {
                                if factory.name() == "ristsink" {
                                    if let Ok(bin) = elem.dynamic_cast::<gstreamer::Bin>() {
                                        if let Some(child) = bin.by_name("rist_send_rtpbin") {
                                            let _ = child.set_property("latency", 2000u32);
                                        }
                                    }
                                }
                            }
                        }
                        gstreamer::glib::ControlFlow::Break
                    });

                    // Quit after duration or on error/EOS, all on this thread-default context
                    let ml_quit = main_loop.clone();
                    let bus = sender_pipeline.bus().expect("bus");
                    let _ = bus.add_watch_local(move |_, msg| {
                        use gstreamer::MessageView;
                        use gstreamer::glib::ControlFlow;
                        match msg.view() {
                            MessageView::Eos(_) | MessageView::Error(_) => {
                                ml_quit.quit();
                                ControlFlow::Break
                            }
                            _ => ControlFlow::Continue,
                        }
                    });

                    // Timeout to stop after duration
                    let ml_quit = main_loop.clone();
                    let _ = gstreamer::glib::timeout_add_seconds_local(duration_secs as u32, move || {
                        ml_quit.quit();
                        gstreamer::glib::ControlFlow::Break
                    });

                    sender_pipeline.set_state(gstreamer::State::Playing).expect("play sender");
                    main_loop.run();
                    let _ = sender_pipeline.set_state(gstreamer::State::Null);
                });
                ();
            });
        });

        // Receiver task in rx0_link_1 (single RIST)
        let receiver_metrics_clone = receiver_metrics.clone();
        let receiver_handle = tokio::task::spawn_blocking(move || {
            let mut ns_mgr = NetNsManager::new().expect("Failed to create NetNsManager");
            ns_mgr.attach_existing_namespace("rx0_link_1").expect("Failed to attach rx0_link_1");
            let output_file = "race_car_test_output.mp4".to_string();

            let _ = ns_mgr.exec_in_namespace("rx0_link_1", || {
                gstreamer::init().ok();
                let receiver_pipeline = build_ts_over_rtp_receiver_pipeline_with_output(
                    rx_port_ts,
                    receiver_metrics_clone.clone(),
                    &output_file,
                ).expect("build receiver");

                // Create a dedicated thread-default GLib MainContext and loop
                let ctx = gstreamer::glib::MainContext::new();
                let _ = ctx.with_thread_default(|| {
                    let main_loop = gstreamer::glib::MainLoop::new(Some(&ctx), false);

                    // Best-effort: increase internal rtpbin latency if present
                    let pipeline_clone = receiver_pipeline.clone();
                    gstreamer::glib::idle_add_local(move || {
                        let mut it = pipeline_clone.iterate_elements();
                        while let Ok(Some(elem)) = it.next() {
                            if let Some(factory) = elem.factory() {
                                if factory.name() == "ristsrc" {
                                    if let Ok(bin) = elem.dynamic_cast::<gstreamer::Bin>() {
                                        if let Some(child) = bin.by_name("rist_recv_rtpbin") {
                                            let _ = child.set_property("latency", 2000u32);
                                        }
                                    }
                                }
                            }
                        }
                        gstreamer::glib::ControlFlow::Break
                    });

                    // Bus watch to quit loop on EOS or Error
                    let ml_quit = main_loop.clone();
                    let bus = receiver_pipeline.bus().expect("bus");
                    let _ = bus.add_watch_local(move |_, msg| {
                        use gstreamer::MessageView;
                        use gstreamer::glib::ControlFlow;
                        match msg.view() {
                            MessageView::Eos(_) | MessageView::Error(_) => {
                                ml_quit.quit();
                                ControlFlow::Break
                            }
                            _ => ControlFlow::Continue,
                        }
                    });

                    // Quit after duration
                    let ml_quit = main_loop.clone();
                    let _ = gstreamer::glib::timeout_add_seconds_local(duration_secs as u32, move || {
                        ml_quit.quit();
                        gstreamer::glib::ControlFlow::Break
                    });

                    receiver_pipeline.set_state(gstreamer::State::Playing).expect("play receiver");
                    main_loop.run();
                    let _ = receiver_pipeline.set_state(gstreamer::State::Null);
                    // Small settle
                    std::thread::sleep(std::time::Duration::from_millis(500));
                });
                ();
            });
        });

        // Periodic progress reports while tasks run
        let mut last_report = Instant::now();
        let report_interval = Duration::from_secs(10);
        while start_time.elapsed().as_secs() < duration_secs {
            sleep(Duration::from_millis(200)).await;
            if last_report.elapsed() >= report_interval {
                let receiver_stats = receiver_metrics.lock().unwrap();
                info!(
                    "Progress: {}s - Received: {} frames, {} KB",
                    start_time.elapsed().as_secs(),
                    receiver_stats.frames_received,
                    receiver_stats.bytes_received / 1024
                );
                last_report = Instant::now();
            }
        }

        // Wait for tasks to finish
        let _ = sender_handle.await;
        let _ = receiver_handle.await;
        
        // Collect final metrics
        let final_receiver_metrics = receiver_metrics.lock().unwrap().clone();
        
        // Assess quality
        let assessment = assess_video_quality(&final_receiver_metrics, duration_secs, "Race Car Cellular Bonding with NetNS");
        
        info!("Test completed in {:.2}s", start_time.elapsed().as_secs_f64());
    info!("Video output saved to: race_car_test_output.mp4");
        
        Ok(assessment)
    }

    /// Run minimal video-only RIST test inside namespaces to isolate transport
    async fn run_video_only_over_netns(duration_secs: u64) -> Result<QualityAssessment, Box<dyn std::error::Error>> {
        info!("Starting minimal video-only RIST test over netns for {}s", duration_secs);

        let rx_port = 8200u16; // use a different port from the other test
        let start_time = Instant::now();

        let (_orchestrator, bonding_addresses) = setup_race_car_network_scenarios(rx_port).await?;
        info!("Netns setup complete for video-only test targeting {}", bonding_addresses.join(","));

        use netns_testbench::netns::Manager as NetNsManager;

        // Metrics
        let receiver_metrics = Arc::new(Mutex::new(VideoQualityMetrics::default()));

        // Sender in tx namespace
        let bonding_addresses_tx = bonding_addresses.clone();
        let sender_handle = tokio::task::spawn_blocking(move || {
            let mut ns_mgr = NetNsManager::new().expect("Failed to create NetNsManager");
            ns_mgr.attach_existing_namespace("tx0_link_1").expect("attach tx ns");
            let _ = ns_mgr.exec_in_namespace("tx0_link_1", || {
                gstreamer::init().ok();
                let sender_pipeline = build_video_only_sender_pipeline(&bonding_addresses_tx).expect("build sender");

                let ctx = gstreamer::glib::MainContext::new();
                let _ = ctx.with_thread_default(|| {
                    let main_loop = gstreamer::glib::MainLoop::new(Some(&ctx), false);

                    // Try to set internal rtpbin latency after elements are created
                    let pipeline_clone = sender_pipeline.clone();
                    gstreamer::glib::idle_add_local(move || {
                        let mut it = pipeline_clone.iterate_elements();
                        while let Ok(Some(elem)) = it.next() {
                            if let Some(factory) = elem.factory() {
                                if factory.name() == "ristsink" {
                                    if let Ok(bin) = elem.dynamic_cast::<gstreamer::Bin>() {
                                        if let Some(child) = bin.by_name("rist_send_rtpbin") {
                                            let _ = child.set_property("latency", 200u32);
                                            break;
                                        }
                                    }
                                }
                            }
                        }
                        gstreamer::glib::ControlFlow::Break
                    });

                    // Bus watch
                    let ml_quit = main_loop.clone();
                    let bus = sender_pipeline.bus().expect("bus");
                    let _ = bus.add_watch_local(move |_, msg| {
                        use gstreamer::MessageView;
                        use gstreamer::glib::ControlFlow;
                        match msg.view() {
                            MessageView::Eos(_) | MessageView::Error(_) => { ml_quit.quit(); ControlFlow::Break }
                            _ => ControlFlow::Continue,
                        }
                    });

                    // Timeout
                    let ml_quit = main_loop.clone();
                    let _ = gstreamer::glib::timeout_add_seconds_local(duration_secs as u32, move || {
                        ml_quit.quit();
                        gstreamer::glib::ControlFlow::Break
                    });

                    sender_pipeline.set_state(gstreamer::State::Playing).expect("play sender");
                    main_loop.run();
                    let _ = sender_pipeline.set_state(gstreamer::State::Null);
                });
                ();
            });
        });

        // Receiver in rx namespace
        let receiver_metrics_clone = receiver_metrics.clone();
        let receiver_handle = tokio::task::spawn_blocking(move || {
            let mut ns_mgr = NetNsManager::new().expect("Failed to create NetNsManager");
            ns_mgr.attach_existing_namespace("rx0_link_1").expect("attach rx ns");
            let output_file = "video_only_output.mp4".to_string();

            let _ = ns_mgr.exec_in_namespace("rx0_link_1", || {
                gstreamer::init().ok();
                let receiver_pipeline = build_video_only_receiver_pipeline_with_output(
                    rx_port,
                    receiver_metrics_clone.clone(),
                    &output_file,
                ).expect("build receiver");

                let ctx = gstreamer::glib::MainContext::new();
                let _ = ctx.with_thread_default(|| {
                    let main_loop = gstreamer::glib::MainLoop::new(Some(&ctx), false);

                    // Try to set internal rtpbin latency
                    let pipeline_clone = receiver_pipeline.clone();
                    gstreamer::glib::idle_add_local(move || {
                        let mut it = pipeline_clone.iterate_elements();
                        while let Ok(Some(elem)) = it.next() {
                            if let Some(factory) = elem.factory() {
                                if factory.name() == "ristsrc" {
                                    if let Ok(bin) = elem.dynamic_cast::<gstreamer::Bin>() {
                                        if let Some(child) = bin.by_name("rist_recv_rtpbin") {
                                            let _ = child.set_property("latency", 200u32);
                                            break;
                                        }
                                    }
                                }
                            }
                        }
                        gstreamer::glib::ControlFlow::Break
                    });

                    // Bus watch
                    let ml_quit = main_loop.clone();
                    let bus = receiver_pipeline.bus().expect("bus");
                    let _ = bus.add_watch_local(move |_, msg| {
                        use gstreamer::MessageView;
                        use gstreamer::glib::ControlFlow;
                        match msg.view() {
                            MessageView::Eos(_) | MessageView::Error(_) => { ml_quit.quit(); ControlFlow::Break }
                            _ => ControlFlow::Continue,
                        }
                    });

                    // Timeout
                    let ml_quit = main_loop.clone();
                    let _ = gstreamer::glib::timeout_add_seconds_local(duration_secs as u32, move || {
                        ml_quit.quit();
                        gstreamer::glib::ControlFlow::Break
                    });

                    receiver_pipeline.set_state(gstreamer::State::Playing).expect("play receiver");
                    main_loop.run();
                    let _ = receiver_pipeline.set_state(gstreamer::State::Null);
                    std::thread::sleep(std::time::Duration::from_millis(250));
                });
                ();
            });
        });

        // Periodic progress
        let mut last_log = Instant::now();
        let interval = Duration::from_secs(5);
        while start_time.elapsed().as_secs() < duration_secs {
            sleep(Duration::from_millis(200)).await;
            if last_log.elapsed() >= interval {
                let m = receiver_metrics.lock().unwrap();
                info!("Video-only progress: {}s - {} frames, {} KB", start_time.elapsed().as_secs(), m.frames_received, m.bytes_received / 1024);
                last_log = Instant::now();
            }
        }

        let _ = sender_handle.await;
        let _ = receiver_handle.await;

        let metrics = receiver_metrics.lock().unwrap().clone();
        let qa = assess_video_quality(&metrics, duration_secs, "Video-only over netns");
        Ok(qa)
    }

    /// Initialize testing environment
    fn init_race_car_test_env() {
        // Initialize GStreamer
        gstreamer::init().expect("Failed to initialize GStreamer");
        
        // Initialize tracing
        if std::env::var("RUST_LOG").is_err() {
            std::env::set_var("RUST_LOG", "info,netns_testbench=debug");
        }
        
        tracing_subscriber::fmt()
            .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
            .try_init()
            .ok();
    }

    /// Main race car integration test
    #[tokio::test]
    #[ignore = "requires CAP_NET_ADMIN privileges for network namespaces"]
    async fn test_race_car_rist_over_challenging_network() {
        init_race_car_test_env();
        
        info!("üèÅ RIST Race Car Challenge Test - Network Namespaces");
        info!("Testing H.265 1080p60 + dual-channel two-tone sine wave audio over 2x4G + 2x5G bonded connections");
        info!("Network conditions: High mobility, terrain blockage, handovers");
        
        let test_duration = 30; // 30 second test
        
        match run_race_car_rist_test(test_duration).await {
            Ok(assessment) => {
                info!("üèÜ RACE CAR TEST RESULTS:");
                info!("Overall Quality Score: {:.1}/100", assessment.overall_score);
                info!("Network Conditions: {}", assessment.network_conditions);
                info!("Bonding Effectiveness: {:.1}%", assessment.bonding_effectiveness);
                info!("Recommendation: {}", assessment.recommendation);
                
                info!("üìä Detailed Metrics:");
                let metrics = &assessment.video_quality;
                info!("  Frames: {} received", metrics.frames_received);
                info!("  Data: {} KB received", metrics.bytes_received / 1024);
                
                // Test assertions
                assert!(assessment.overall_score >= 50.0, 
                       "Video quality score too low: {:.1}/100", assessment.overall_score);
                assert!(metrics.frames_received > 0, "No frames received");
                
                info!("‚úÖ Race car RIST test PASSED!");
                
            },
            Err(e) => {
                error!("‚ùå Race car RIST test FAILED: {}", e);
                
                if e.to_string().contains("Permission denied") || e.to_string().contains("Operation not permitted") {
                    info!("üí° This test requires CAP_NET_ADMIN capability.");
                    info!("   Run with: sudo -E cargo test test_race_car_rist_over_challenging_network -- --ignored");
                    info!("   Or set capability: sudo setcap cap_net_admin+ep target/debug/deps/netns_race_car_integration-*");
                }
                
                panic!("Race car test failed: {}", e);
            }
        }
    }

    /// Quick smoke test that can run without privileges (using localhost simulation)
    #[tokio::test(flavor = "multi_thread")]
    async fn test_race_car_pipeline_smoke_test() {
        init_race_car_test_env();
        
        info!("üöó Race Car Pipeline Smoke Test (localhost simulation)");
        
        // Use localhost addresses for smoke test
        let bonding_addresses = vec![
            "127.0.0.1:9000".to_string(),
            "127.0.0.1:9002".to_string(),
        ];
        
        // Test pipeline creation
        let (sender_pipeline, _sender_metrics) = build_race_car_sender_pipeline(&bonding_addresses)
            .expect("Failed to build sender pipeline");
            
        let (receiver_pipeline, _receiver_metrics) = build_race_car_receiver_pipeline(9100)
            .expect("Failed to build receiver pipeline");
        
        // Test state transitions
        sender_pipeline.set_state(gstreamer::State::Ready)
            .expect("Failed to set sender to ready");
        receiver_pipeline.set_state(gstreamer::State::Ready)
            .expect("Failed to set receiver to ready");
        
        // Clean shutdown
        sender_pipeline.set_state(gstreamer::State::Null)
            .expect("Failed to stop sender");
        receiver_pipeline.set_state(gstreamer::State::Null)
            .expect("Failed to stop receiver");
        
        info!("‚úÖ Pipeline smoke test passed!");
    }

    /// Full race car integration test with network namespaces and video output
    #[tokio::test(flavor = "multi_thread")]
    #[ignore = "requires CAP_NET_ADMIN privileges for network namespaces"]
    async fn test_race_car_with_netns_and_video_output() {
        init_race_car_test_env();
        
        info!("üèÅ RIST Race Car Test - Full NetNS Integration with Video Output");
        info!("Duration: 60s, Output: race_car_test_output.mp4");
        
        let test_duration = 60; // 1 minute as requested
        
        match run_race_car_rist_test_with_video_output(test_duration).await {
            Ok(assessment) => {
                info!("üèÜ RACE CAR TEST WITH VIDEO OUTPUT COMPLETED:");
                info!("Overall Quality Score: {:.1}/100", assessment.overall_score);
                info!("Network Conditions: {}", assessment.network_conditions);
                info!("Bonding Effectiveness: {:.1}%", assessment.bonding_effectiveness);
                info!("Video Output: race_car_test_output.mp4");
                info!("Recommendation: {}", assessment.recommendation);
                
                info!("üìä Detailed Metrics:");
                let metrics = &assessment.video_quality;
                info!("  Frames: {} received", metrics.frames_received);
                info!("  Data: {} KB received", metrics.bytes_received / 1024);
                
                // Test assertions
                assert!(assessment.overall_score >= 40.0, 
                       "Video quality score too low for challenging conditions: {:.1}/100", assessment.overall_score);
                assert!(metrics.frames_received > 0, "No frames received");
                
                info!("‚úÖ Full race car RIST test with video output PASSED!");
                
            },
            Err(e) => {
                error!("‚ùå Race car RIST test FAILED: {}", e);
                
                if e.to_string().contains("Permission denied") || e.to_string().contains("Operation not permitted") {
                    info!("üí° This test requires CAP_NET_ADMIN capability.");
                    info!("   Run with: sudo -E cargo test test_race_car_with_netns_and_video_output --features netns-sim --package rist-elements -- --ignored --nocapture");
                    panic!("Insufficient privileges for network namespace test");
                } else {
                    panic!("Race car test failed: {}", e);
                }
            }
        }
    }

    /// Minimal video-only transport sanity test over netns
    #[tokio::test(flavor = "multi_thread")]
    #[ignore = "requires CAP_NET_ADMIN privileges for network namespaces"]
    async fn test_video_only_over_netns() {
        init_race_car_test_env();
        info!("üèÅ Minimal video-only RIST over netns (30s)");

        let duration = 30u64;
        match run_video_only_over_netns(duration).await {
            Ok(assessment) => {
                let m = &assessment.video_quality;
                info!("Frames: {} bytes: {}", m.frames_received, m.bytes_received);
                assert!(m.frames_received > 0, "No frames received in video-only test");
            }
            Err(e) => {
                error!("video-only netns test failed: {}", e);
                if e.to_string().contains("Permission denied") || e.to_string().contains("Operation not permitted") {
                    panic!("Insufficient privileges for network namespace test");
                } else {
                    panic!("{}", e);
                }
            }
        }
    }

    // Dual-session test removed in favor of single-session MPEG-TS over RTP
}

#[cfg(not(feature = "netns-sim"))]
#[tokio::test]
async fn test_netns_feature_disabled() {
    println!("‚ö†Ô∏è  netns-sim feature is disabled. To run race car tests:");
    println!("   cargo test --features netns-sim --package rist-elements");
}